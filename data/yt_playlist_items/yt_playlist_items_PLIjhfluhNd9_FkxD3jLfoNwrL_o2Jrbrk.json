{
  "_id": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
  "as_of": "2021-12-10 00:22:00.211636",
  "items": [
    {
      "kind": "youtube#playlistItem",
      "etag": "Jec9nXBQbDGRJpyFaqRBSvxA38g",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4yMUQyQTQzMjRDNzMyQTMy",
      "snippet": {
        "publishedAt": "2021-11-10T13:36:38Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "9. Markov Rewards and Dynamic Programming",
        "description": "MIT 6.262 Discrete Stochastic Processes, Spring 2011\nView the complete course: http://ocw.mit.edu/6-262S11\nInstructor: Robert Gallager\n\nLicense: Creative Commons BY-NC-SA\nMore information at http://ocw.mit.edu/terms\nMore courses at http://ocw.mit.edu",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/mNGVkKeMUtc/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/mNGVkKeMUtc/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/mNGVkKeMUtc/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/mNGVkKeMUtc/sddefault.jpg",
            "width": 640,
            "height": 480
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 0,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "mNGVkKeMUtc"
        },
        "videoOwnerChannelTitle": "MIT OpenCourseWare",
        "videoOwnerChannelId": "UCEBb1b_L6zDS3xTUrIALZOw"
      },
      "contentDetails": {
        "videoId": "mNGVkKeMUtc",
        "videoPublishedAt": "2012-06-29T19:44:57Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "_aNrOt-g50lDmATQfL5PQDuyR3Y",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4zMDg5MkQ5MEVDMEM1NTg2",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Process (MDP) Tutorial",
        "description": "We explain what an MDP is and how utility values are defined within an MDP. Course playlist at https://www.youtube.com/playlist?list=PLSx7bGPy9gbHivKzRg2enzdABgKUd3u-E",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/DgRqxKt2DYE/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/DgRqxKt2DYE/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/DgRqxKt2DYE/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/DgRqxKt2DYE/sddefault.jpg",
            "width": 640,
            "height": 480
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 1,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "DgRqxKt2DYE"
        },
        "videoOwnerChannelTitle": "Jos\u00e9 Vidal",
        "videoOwnerChannelId": "UCPRGFaBrWC5pknqe6WkTCqw"
      },
      "contentDetails": {
        "videoId": "DgRqxKt2DYE",
        "videoPublishedAt": "2012-12-16T13:30:23Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "ad1fAGRDOW1XIk-SA4L4-om-hJw",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4xMkVGQjNCMUM1N0RFNEUx",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Machine learning - Bayesian optimization and multi-armed bandits",
        "description": "Bayesian optimization, Thompson sampling and multi-armed bandits. Applications to algorithm configuration, intelligent user interfaces, advertising, control and other decision problems.\nSlides available at: http://www.cs.ubc.ca/~nando/540-2013/lectures.html\nCourse taught in 2013 at UBC by Nando de Freitas",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/vz3D36VXefI/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/vz3D36VXefI/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/vz3D36VXefI/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/vz3D36VXefI/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/vz3D36VXefI/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 2,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "vz3D36VXefI"
        },
        "videoOwnerChannelTitle": "Nando de Freitas",
        "videoOwnerChannelId": "UC0z_jCi0XWqI8awUuQRFnyw"
      },
      "contentDetails": {
        "videoId": "vz3D36VXefI",
        "videoPublishedAt": "2013-02-12T19:58:46Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "e4wAZU5JECQDGDfvTYWXtL2RQNY",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay45RjNFMDhGQ0Q2RkFCQTc1",
      "snippet": {
        "publishedAt": "2021-11-11T10:56:28Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture7: Expectimax and Utilities",
        "description": "CS188 Artificial Intelligence\nUC Berkeley, Spring 2013\nInstructor: Prof. Pieter Abbeel",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/r-RxPnnp__o/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/r-RxPnnp__o/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/r-RxPnnp__o/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/r-RxPnnp__o/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/r-RxPnnp__o/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 3,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "r-RxPnnp__o"
        },
        "videoOwnerChannelTitle": "CS188Spring2013",
        "videoOwnerChannelId": "UCTmAYxRV7H9NTdgC9bNixvw"
      },
      "contentDetails": {
        "videoId": "r-RxPnnp__o",
        "videoPublishedAt": "2013-02-14T00:49:39Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "jZAntjHFJzzgeKQSckpn9Kve6y4",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4wMTcyMDhGQUE4NTIzM0Y5",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 8: Markov Decision Processes (MDPs)",
        "description": "CS188 Artificial Intelligence\nUC Berkeley, Spring 2013\nInstructor: Prof. Pieter Abbeel",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/i0o-ui1N35U/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/i0o-ui1N35U/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/i0o-ui1N35U/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/i0o-ui1N35U/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/i0o-ui1N35U/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 4,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "i0o-ui1N35U"
        },
        "videoOwnerChannelTitle": "CS188Spring2013",
        "videoOwnerChannelId": "UCTmAYxRV7H9NTdgC9bNixvw"
      },
      "contentDetails": {
        "videoId": "i0o-ui1N35U",
        "videoPublishedAt": "2013-02-15T03:39:26Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "R5G7uH5sa-44JzVrfW2dozIMtLI",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay41MzJCQjBCNDIyRkJDN0VD",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 9: Markov Decision Process II",
        "description": "CS188 Artificial Intelligence\nUC Berkeley, Spring 2013\nInstructor: Prof. Pieter Abbeel",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/Csiiv6WGzKM/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/Csiiv6WGzKM/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/Csiiv6WGzKM/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/Csiiv6WGzKM/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/Csiiv6WGzKM/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 5,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "Csiiv6WGzKM"
        },
        "videoOwnerChannelTitle": "CS188Spring2013",
        "videoOwnerChannelId": "UCTmAYxRV7H9NTdgC9bNixvw"
      },
      "contentDetails": {
        "videoId": "Csiiv6WGzKM",
        "videoPublishedAt": "2013-02-20T10:20:29Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "Smn2s6c0dVHQ_jUVSWhkt-0b8hs",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay45NzUwQkI1M0UxNThBMkU0",
      "snippet": {
        "publishedAt": "2021-11-11T10:20:58Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 10: Reinforcement Learning",
        "description": "CS188 Artificial Intelligence\nUC Berkeley, CS188\nInstructor: Prof. Pieter Abbeel",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/ifma8G7LegE/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/ifma8G7LegE/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/ifma8G7LegE/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/ifma8G7LegE/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/ifma8G7LegE/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 6,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "ifma8G7LegE"
        },
        "videoOwnerChannelTitle": "CS188Spring2013",
        "videoOwnerChannelId": "UCTmAYxRV7H9NTdgC9bNixvw"
      },
      "contentDetails": {
        "videoId": "ifma8G7LegE",
        "videoPublishedAt": "2013-02-22T09:31:08Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "1rAsnX-56STrWIvVu0fcoEiQjwc",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay40QTA3NTU2RkM1QzlCMzYx",
      "snippet": {
        "publishedAt": "2021-11-11T10:56:49Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 11: Reinforcement Learning II",
        "description": "CS188 Artificial Intelligence\nUC Berkeley, Spring 2013\nInstructor: Prof. Pieter Abbeel",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/Si1_YTw960c/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/Si1_YTw960c/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/Si1_YTw960c/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/Si1_YTw960c/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/Si1_YTw960c/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 7,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "Si1_YTw960c"
        },
        "videoOwnerChannelTitle": "CS188Spring2013",
        "videoOwnerChannelId": "UCTmAYxRV7H9NTdgC9bNixvw"
      },
      "contentDetails": {
        "videoId": "Si1_YTw960c",
        "videoPublishedAt": "2013-02-27T04:33:59Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "QWi5rWY_ptfz5NA45rt_RY75x3o",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5BRjJDODk5REM0NjkzMUIy",
      "snippet": {
        "publishedAt": "2021-11-15T07:53:52Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 7: Uncertainty and Utilities",
        "description": "CS188 Artificial Intelligence, Fall 2013\nInstructor: Prof. Dan Klein",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/M98BM_yJPNw/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/M98BM_yJPNw/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/M98BM_yJPNw/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/M98BM_yJPNw/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/M98BM_yJPNw/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 8,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "M98BM_yJPNw"
        },
        "videoOwnerChannelTitle": "CS188Fall2013",
        "videoOwnerChannelId": "UCshmLD2MsyqAKBx8ctivb5Q"
      },
      "contentDetails": {
        "videoId": "M98BM_yJPNw",
        "videoPublishedAt": "2013-09-20T04:59:03Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "STI84Gs3ll2pvPsyd8g33WzklgY",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5DQ0MyQ0Y4Mzg0M0VGOEYw",
      "snippet": {
        "publishedAt": "2021-11-11T10:22:46Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 9: MDPs II",
        "description": "",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/6pBvbLyn6fE/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/6pBvbLyn6fE/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/6pBvbLyn6fE/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/6pBvbLyn6fE/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/6pBvbLyn6fE/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 9,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "6pBvbLyn6fE"
        },
        "videoOwnerChannelTitle": "CS188 Spring 2014",
        "videoOwnerChannelId": "UCB4_W1V-KfwpTLxH9jG1_iA"
      },
      "contentDetails": {
        "videoId": "6pBvbLyn6fE",
        "videoPublishedAt": "2014-02-19T08:47:38Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "5Ogn3qza0e4hec8NU1bC52PE0_Y",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5DNzE1RjZEMUZCMjA0RDBB",
      "snippet": {
        "publishedAt": "2021-11-11T10:21:31Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 10  Reinforcement Learning I",
        "description": "",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/IXuHxkpO5E8/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/IXuHxkpO5E8/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/IXuHxkpO5E8/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/IXuHxkpO5E8/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/IXuHxkpO5E8/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 10,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "IXuHxkpO5E8"
        },
        "videoOwnerChannelTitle": "CS188 Spring 2014",
        "videoOwnerChannelId": "UCB4_W1V-KfwpTLxH9jG1_iA"
      },
      "contentDetails": {
        "videoId": "IXuHxkpO5E8",
        "videoPublishedAt": "2014-02-21T09:02:34Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "RYKexJbd0Hw9xPrF6oWrNK-7-rg",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay41NkI0NEY2RDEwNTU3Q0M2",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes",
        "description": "Virginia Tech CS5804",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/KovN7WKI9Y0/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/KovN7WKI9Y0/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/KovN7WKI9Y0/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/KovN7WKI9Y0/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/KovN7WKI9Y0/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 11,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "KovN7WKI9Y0"
        },
        "videoOwnerChannelTitle": "Bert Huang",
        "videoOwnerChannelId": "UCleP-FrLBsyu33GUShi3XaQ"
      },
      "contentDetails": {
        "videoId": "KovN7WKI9Y0",
        "videoPublishedAt": "2015-02-13T02:49:56Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "ccHBKDXtARFRx3NTPi2DEsR-8Wc",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4yODlGNEE0NkRGMEEzMEQy",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes Continued",
        "description": "Virginia Tech CS 5804",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/ts4_VPoBT44/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/ts4_VPoBT44/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/ts4_VPoBT44/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/ts4_VPoBT44/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/ts4_VPoBT44/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 12,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "ts4_VPoBT44"
        },
        "videoOwnerChannelTitle": "Bert Huang",
        "videoOwnerChannelId": "UCleP-FrLBsyu33GUShi3XaQ"
      },
      "contentDetails": {
        "videoId": "ts4_VPoBT44",
        "videoPublishedAt": "2015-02-18T20:52:02Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "5IrAYgZzxYWcpi3qU2K88pE79vQ",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4yMDhBMkNBNjRDMjQxQTg1",
      "snippet": {
        "publishedAt": "2021-11-10T20:38:56Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes Three - Georgia Tech - Machine Learning",
        "description": "Watch on Udacity: https://www.udacity.com/course/viewer#!/c-ud262/l-684808907/m-699548544\nCheck out the full Advanced Operating Systems course for free at: https://www.udacity.com/course/ud262 \nGeorgia Tech online Master's program: https://www.udacity.com/georgia-tech",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/Jw3ZnWFjDfM/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/Jw3ZnWFjDfM/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/Jw3ZnWFjDfM/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/Jw3ZnWFjDfM/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/Jw3ZnWFjDfM/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 13,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "Jw3ZnWFjDfM"
        },
        "videoOwnerChannelTitle": "Udacity",
        "videoOwnerChannelId": "UCBVCi5JbYmfG3q5MEuoWdOw"
      },
      "contentDetails": {
        "videoId": "Jw3ZnWFjDfM",
        "videoPublishedAt": "2015-02-23T19:49:26Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "IB0y8Ga7Pg4A4hMoNdMytGKgwTQ",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5EQUE1NTFDRjcwMDg0NEMz",
      "snippet": {
        "publishedAt": "2021-11-08T16:43:58Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes - Georgia Tech - Machine Learning",
        "description": "Check out the full Advanced Operating Systems course for free at: https://www.udacity.com/course/ud262 \nGeorgia Tech online Master's program: https://www.udacity.com/georgia-tech",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/Jk2V9yA82YU/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/Jk2V9yA82YU/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/Jk2V9yA82YU/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/Jk2V9yA82YU/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/Jk2V9yA82YU/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 14,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "Jk2V9yA82YU"
        },
        "videoOwnerChannelTitle": "Udacity",
        "videoOwnerChannelId": "UCBVCi5JbYmfG3q5MEuoWdOw"
      },
      "contentDetails": {
        "videoId": "Jk2V9yA82YU",
        "videoPublishedAt": "2015-02-23T19:51:30Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "LqqZhfgxnHK8kJ-E-8aSU5pjSv8",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5ENDU4Q0M4RDExNzM1Mjcy",
      "snippet": {
        "publishedAt": "2021-11-10T20:38:44Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes Two - Georgia Tech - Machine Learning",
        "description": "Watch on Udacity: https://www.udacity.com/course/viewer#!/c-ud262/l-684808907/m-651230865\nCheck out the full Advanced Operating Systems course for free at: https://www.udacity.com/course/ud262 \nGeorgia Tech online Master's program: https://www.udacity.com/georgia-tech",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/BxIG76-C37k/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/BxIG76-C37k/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/BxIG76-C37k/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/BxIG76-C37k/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/BxIG76-C37k/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 15,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "BxIG76-C37k"
        },
        "videoOwnerChannelTitle": "Udacity",
        "videoOwnerChannelId": "UCBVCi5JbYmfG3q5MEuoWdOw"
      },
      "contentDetails": {
        "videoId": "BxIG76-C37k",
        "videoPublishedAt": "2015-02-23T19:51:31Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "LnGqowKV8ux9c2UppqJyndaETQk",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay45RTgxNDRBMzUwRjQ0MDhC",
      "snippet": {
        "publishedAt": "2021-11-10T13:50:50Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes Four - Georgia Tech - Machine Learning",
        "description": "Check out the full Advanced Operating Systems course for free at: https://www.udacity.com/course/ud262 \nGeorgia Tech online Master's program: https://www.udacity.com/georgia-tech",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/dkBZ9YKuOVA/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/dkBZ9YKuOVA/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/dkBZ9YKuOVA/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/dkBZ9YKuOVA/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/dkBZ9YKuOVA/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 16,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "dkBZ9YKuOVA"
        },
        "videoOwnerChannelTitle": "Udacity",
        "videoOwnerChannelId": "UCBVCi5JbYmfG3q5MEuoWdOw"
      },
      "contentDetails": {
        "videoId": "dkBZ9YKuOVA",
        "videoPublishedAt": "2015-02-23T19:51:31Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "L_5fkcK83x38AaeddB13uS3gLFk",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5GM0Q3M0MzMzY5NTJFNTdE",
      "snippet": {
        "publishedAt": "2021-11-10T20:39:11Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Policies - Georgia Tech - Machine Learning",
        "description": "Watch on Udacity: https://www.udacity.com/course/viewer#!/c-ud262/l-684808907/m-651230882\nCheck out the full Advanced Operating Systems course for free at: https://www.udacity.com/course/ud262 \nGeorgia Tech online Master's program: https://www.udacity.com/georgia-tech",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/jDYwHB9VDmM/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/jDYwHB9VDmM/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/jDYwHB9VDmM/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/jDYwHB9VDmM/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/jDYwHB9VDmM/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 17,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "jDYwHB9VDmM"
        },
        "videoOwnerChannelTitle": "Udacity",
        "videoOwnerChannelId": "UCBVCi5JbYmfG3q5MEuoWdOw"
      },
      "contentDetails": {
        "videoId": "jDYwHB9VDmM",
        "videoPublishedAt": "2015-02-23T19:51:33Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "kMVYnTLINbkwt5hnRNopkqs0VvM",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4zRjM0MkVCRTg0MkYyQTM0",
      "snippet": {
        "publishedAt": "2021-11-10T20:50:44Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Finding Policies - Georgia Tech - Machine Learning",
        "description": "Watch on Udacity: https://www.udacity.com/course/viewer#!/c-ud262/l-684808907/m-651230884\nCheck out the full Advanced Operating Systems course for free at: https://www.udacity.com/course/ud262 \nGeorgia Tech online Master's program: https://www.udacity.com/georgia-tech",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/3MgwqSU_Snw/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/3MgwqSU_Snw/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/3MgwqSU_Snw/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/3MgwqSU_Snw/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/3MgwqSU_Snw/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 18,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "3MgwqSU_Snw"
        },
        "videoOwnerChannelTitle": "Udacity",
        "videoOwnerChannelId": "UCBVCi5JbYmfG3q5MEuoWdOw"
      },
      "contentDetails": {
        "videoId": "3MgwqSU_Snw",
        "videoPublishedAt": "2015-02-23T19:51:33Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "0PI_yseyH663Y1NQxfx7piV3QgY",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4wOTA3OTZBNzVEMTUzOTMy",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "RL Course by David Silver - Lecture 2: Markov Decision Process",
        "description": "#Reinforcement Learning Course by David Silver# Lecture 2:  Markov Decision Process\n\n#Slides and more info about the course: http://goo.gl/vUiyjq",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/lfHX2hHRMVQ/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/lfHX2hHRMVQ/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/lfHX2hHRMVQ/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/lfHX2hHRMVQ/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/lfHX2hHRMVQ/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 19,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "lfHX2hHRMVQ"
        },
        "videoOwnerChannelTitle": "DeepMind",
        "videoOwnerChannelId": "UCP7jMXSY2xbc3KCAE0MHQ-A"
      },
      "contentDetails": {
        "videoId": "lfHX2hHRMVQ",
        "videoPublishedAt": "2015-05-13T10:58:40Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "WljLQ65U4UAxDw3ERLzU9TmYMko",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5DMkU4NTY1QUFGQTYwMDE3",
      "snippet": {
        "publishedAt": "2021-11-11T10:23:08Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Deep RL Bootcamp  Lecture 4A: Policy Gradients",
        "description": "Instructor: Pieter Abbeel\nLecture 4A Deep RL Bootcamp Berkeley August 2017\nPolicy Gradients",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/S_gwYj1Q-44/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/S_gwYj1Q-44/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/S_gwYj1Q-44/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/S_gwYj1Q-44/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/S_gwYj1Q-44/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 20,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "S_gwYj1Q-44"
        },
        "videoOwnerChannelTitle": "AI Prism",
        "videoOwnerChannelId": "UCTgM-VlXKuylPrZ_YGAJHOw"
      },
      "contentDetails": {
        "videoId": "S_gwYj1Q-44",
        "videoPublishedAt": "2017-10-05T22:11:01Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "F-zTGwKMeXKRam0Abe753yfiloM",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay43MTI1NDIwOTMwQjIxMzNG",
      "snippet": {
        "publishedAt": "2021-11-11T10:21:49Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "An Introduction to Markov Decision Processes and Reinforcement Learning",
        "description": "RLPy: https://rlpy.readthedocs.io/en/latest/\nAI Gym: https://gym.openai.com/\nTutorial Paper:  A Tutorial on Linear Function Approximators for Dynamic Programming and Reinforcement Learning (http://alborz-geramifard.com/Files/13FTML-RLTutorial.pdf)",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/jpmZp3eX-wI/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/jpmZp3eX-wI/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/jpmZp3eX-wI/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/jpmZp3eX-wI/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/jpmZp3eX-wI/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 21,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "jpmZp3eX-wI"
        },
        "videoOwnerChannelTitle": "Alborz Geramifard",
        "videoOwnerChannelId": "UCjB74dJJ_sNtxzHxGxN7eow"
      },
      "contentDetails": {
        "videoId": "jpmZp3eX-wI",
        "videoPublishedAt": "2018-05-02T16:19:16Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "bNRzOdnwfmRjKUZemdlZtAY5PG0",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4yQUE2Q0JEMTk4NTM3RTZC",
      "snippet": {
        "publishedAt": "2021-11-11T10:22:54Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "CS885 Lecture 2a: Markov Decision Processes",
        "description": "",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/SWYceQpEVKM/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/SWYceQpEVKM/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/SWYceQpEVKM/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/SWYceQpEVKM/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/SWYceQpEVKM/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 22,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "SWYceQpEVKM"
        },
        "videoOwnerChannelTitle": "Pascal Poupart",
        "videoOwnerChannelId": "UC7ZVvEo7-B7lA6LY2MVX72A"
      },
      "contentDetails": {
        "videoId": "SWYceQpEVKM",
        "videoPublishedAt": "2018-05-08T15:13:55Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "KA5t0KDk28PD40GdtYRFOkGEhxY",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay41Mzk2QTAxMTkzNDk4MDhF",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "CS885 Lecture 15c: Semi-Markov Decision Processes",
        "description": "",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/1nuTmzqKQyE/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/1nuTmzqKQyE/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/1nuTmzqKQyE/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/1nuTmzqKQyE/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/1nuTmzqKQyE/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 23,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "1nuTmzqKQyE"
        },
        "videoOwnerChannelTitle": "Pascal Poupart",
        "videoOwnerChannelId": "UC7ZVvEo7-B7lA6LY2MVX72A"
      },
      "contentDetails": {
        "videoId": "1nuTmzqKQyE",
        "videoPublishedAt": "2018-06-21T15:46:11Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "kpOCUDcy-M043JeaBZwYLh9BFSc",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5GNjNDRDREMDQxOThCMDQ2",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Bellman Equation Basics for Reinforcement Learning",
        "description": "An introduction to the Bellman Equations for Reinforcement Learning.\n\nPart of the free Move 37 Reinforcement Learning course at The School of AI.\nhttps://www.theschool.ai/courses/move-37-course/",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/14BfO5lMiuk/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/14BfO5lMiuk/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/14BfO5lMiuk/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/14BfO5lMiuk/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/14BfO5lMiuk/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 24,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "14BfO5lMiuk"
        },
        "videoOwnerChannelTitle": "Skowster the Geek",
        "videoOwnerChannelId": "UCrRTWfso9OS3D09-QSLA5jg"
      },
      "contentDetails": {
        "videoId": "14BfO5lMiuk",
        "videoPublishedAt": "2018-09-19T01:24:22Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "ZCeL5B3bKpzGFf_lZre6wh6bQVg",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5CMEQ2Mjk5NTc3NDZFRUNB",
      "snippet": {
        "publishedAt": "2021-11-11T10:24:52Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Processes",
        "description": "In this video, I introduce the Markov Decision Processes framework, and I give some examples of when the Markov property does not hold.\n\n\nThe corresponding slides are available here:\nhttp://pages.isir.upmc.fr/~sigaud/teach/mdp.pdf",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/e9GxQp-LONU/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/e9GxQp-LONU/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/e9GxQp-LONU/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/e9GxQp-LONU/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/e9GxQp-LONU/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 25,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "e9GxQp-LONU"
        },
        "videoOwnerChannelTitle": "Olivier Sigaud",
        "videoOwnerChannelId": "UCLRpWDzTRLlQn7lMRwvK8Hg"
      },
      "contentDetails": {
        "videoId": "e9GxQp-LONU",
        "videoPublishedAt": "2018-10-12T08:47:11Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "kzYFTD3iiAYleJ-SPzlFOrIwUo0",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay43NDhFRTgwOTRERTU4Rjg3",
      "snippet": {
        "publishedAt": "2021-11-11T10:23:58Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Reinforcement Learning 3: Markov Decision Processes and Dynamic Programming",
        "description": "Hado van Hasselt, Research scientist, discusses the Markov decision processes and dynamic programming as part of the Advanced Deep Learning & Reinforcement Learning Lectures.",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/hMbxmRyDw5M/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/hMbxmRyDw5M/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/hMbxmRyDw5M/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/hMbxmRyDw5M/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/hMbxmRyDw5M/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 26,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "hMbxmRyDw5M"
        },
        "videoOwnerChannelTitle": "DeepMind",
        "videoOwnerChannelId": "UCP7jMXSY2xbc3KCAE0MHQ-A"
      },
      "contentDetails": {
        "videoId": "hMbxmRyDw5M",
        "videoPublishedAt": "2018-11-23T11:25:52Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "IyMn4xdLEb0j-enC28rONvcuizA",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay45ODRDNTg0QjA4NkFBNkQy",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "introduction to Markov Decision Processes (MFD)",
        "description": "This  is a basic intro to MDPx and value iteration to solve them..",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/HmcyDQZbEFs/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/HmcyDQZbEFs/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/HmcyDQZbEFs/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/HmcyDQZbEFs/sddefault.jpg",
            "width": 640,
            "height": 480
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 27,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "HmcyDQZbEFs"
        },
        "videoOwnerChannelTitle": "Francisco Iacobelli",
        "videoOwnerChannelId": "UCzO8FFsWxGdzr1rMAPtbUog"
      },
      "contentDetails": {
        "videoId": "HmcyDQZbEFs",
        "videoPublishedAt": "2018-12-05T01:22:15Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "O1Qa_U2XPO6CWge2jvprs4al3E8",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4xOTEzQzhBQzU3MDNDNjcz",
      "snippet": {
        "publishedAt": "2021-11-17T13:57:54Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Reinforcement Learning Course - Full Machine Learning Tutorial",
        "description": "Reinforcement learning is an area of machine learning that involves taking right action to maximize reward in a particular situation. In this full tutorial course, you will get a solid foundation in reinforcement learning core topics.\n\nThe course covers Q learning, SARSA, double Q learning, deep Q learning, and policy gradient methods. These algorithms are employed in a number of environments from the open AI gym, including space invaders, breakout, and others. The deep learning portion uses Tensorflow and PyTorch.\n\nThe course begins with more modern algorithms, such as deep q learning and policy gradient methods, and demonstrates the power of reinforcement learning.\n\nThen the course teaches some of the fundamental concepts that power all reinforcement learning algorithms. These are illustrated by coding up some algorithms that predate deep learning, but are still foundational to the cutting edge. These are studied in some of the more traditional environments from the OpenAI gym, like the cart pole problem.\n\n\ud83d\udcbbCode: https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning\n\n\u2b50\ufe0f Course Contents \u2b50\ufe0f\n\u2328\ufe0f (00:00:00) Intro \n\u2328\ufe0f (00:01:30) Intro to Deep Q Learning \n\u2328\ufe0f (00:08:56) How to Code Deep Q Learning in Tensorflow \n\u2328\ufe0f (00:52:03) Deep Q Learning with Pytorch Part 1: The Q Network \n\u2328\ufe0f (01:06:21) Deep Q Learning with Pytorch part 2: Coding the Agent \n\u2328\ufe0f (01:28:54) Deep Q Learning with Pytorch part\n\u2328\ufe0f (01:46:39) Intro to Policy Gradients  3: Coding the main loop \n\u2328\ufe0f (01:55:01) How to Beat Lunar Lander with Policy Gradients \n\u2328\ufe0f (02:21:32) How to Beat Space Invaders with Policy Gradients \n\u2328\ufe0f (02:34:41) How to Create Your Own Reinforcement Learning Environment Part 1 \n\u2328\ufe0f (02:55:39) How to Create Your Own Reinforcement Learning Environment Part 2 \n\u2328\ufe0f (03:08:20) Fundamentals of Reinforcement Learning \n\u2328\ufe0f (03:17:09) Markov Decision Processes \n\u2328\ufe0f (03:23:02) The Explore Exploit Dilemma \n\u2328\ufe0f (03:29:19) Reinforcement Learning in the Open AI Gym: SARSA \n\u2328\ufe0f (03:39:56) Reinforcement Learning in the Open AI Gym: Double Q Learning \n\u2328\ufe0f (03:54:07) Conclusion \n\nCourse from Machine Learning with Phil. Check out his YouTube channel: https://www.youtube.com/channel/UC58v9cLitc8VaCjrcKyAbrw\n\n--\n\nLearn to code for free and get a developer job: https://www.freecodecamp.org\n\nRead hundreds of articles on programming: https://medium.freecodecamp.org\n\nAnd subscribe for new videos on technology every day: https://youtube.com/subscription_center?add_user=freecodecamp",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/ELE2_Mftqoc/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/ELE2_Mftqoc/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/ELE2_Mftqoc/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/ELE2_Mftqoc/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/ELE2_Mftqoc/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 28,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "ELE2_Mftqoc"
        },
        "videoOwnerChannelTitle": "freeCodeCamp.org",
        "videoOwnerChannelId": "UC8butISFwT-Wl7EV0hUK0BQ"
      },
      "contentDetails": {
        "videoId": "ELE2_Mftqoc",
        "videoPublishedAt": "2019-05-14T12:19:37Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "LRZFIVefeLK2kYcTU_hLy1jsGII",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay40NzZCMERDMjVEN0RFRThB",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Markov Decision Process - Reinforcement Learning Chapter 3",
        "description": "Free PDF: http://incompleteideas.net/book/RLbook2018.pdf\nPrint Version: https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262039249/ref=dp_ob_title_bk\n\nThanks for watching this series going through the Introduction to Reinforcement Learning book! I think this is the best book for learning RL and hopefully these videos can help shed light on some of the topics as you read through it yourself! \nThanks for watching! Please Subscribe!",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/U24wlvcxXBg/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/U24wlvcxXBg/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/U24wlvcxXBg/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/U24wlvcxXBg/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/U24wlvcxXBg/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 29,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "U24wlvcxXBg"
        },
        "videoOwnerChannelTitle": "Henry AI Labs",
        "videoOwnerChannelId": "UCHB9VepY6kYvZjj0Bgxnpbw"
      },
      "contentDetails": {
        "videoId": "U24wlvcxXBg",
        "videoPublishedAt": "2019-09-30T20:53:39Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "gV1cNNkZbxvqqwg8iWpmANL7bXQ",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay41MjE1MkI0OTQ2QzJGNzNG",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 7: Markov Decision Processes - Value Iteration | Stanford CS221: AI (Autumn 2019)",
        "description": "For more information about Stanford\u2019s Artificial Intelligence professional and graduate programs, visit: https://stanford.io/3pUNqG7\n\nTopics: MDP1, Search review, Project\nPercy Liang, Associate Professor & Dorsa Sadigh, Assistant Professor - Stanford University\nhttp://onlinehub.stanford.edu/\n\nAssociate Professor Percy Liang \nAssociate Professor of Computer Science and Statistics (courtesy)\nhttps://profiles.stanford.edu/percy-liang\n\nAssistant Professor Dorsa Sadigh\nAssistant Professor in the Computer Science Department & Electrical Engineering Department\nhttps://profiles.stanford.edu/dorsa-sadigh\n \nTo follow along with the course schedule and syllabus, visit: \nhttps://stanford-cs221.github.io/autumn2019/#schedule",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/9g32v7bK3Co/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/9g32v7bK3Co/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/9g32v7bK3Co/hqdefault.jpg",
            "width": 480,
            "height": 360
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 30,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "9g32v7bK3Co"
        },
        "videoOwnerChannelTitle": "stanfordonline",
        "videoOwnerChannelId": "UCBa5G_ESCn8Yd4vw5U-gIcg"
      },
      "contentDetails": {
        "videoId": "9g32v7bK3Co",
        "videoPublishedAt": "2020-01-08T19:24:34Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "rTlafF6qFPm8YeoTxLTc6qko4mc",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay44Mjc5REFBRUE2MTdFRDU0",
      "snippet": {
        "publishedAt": "2021-11-11T10:23:20Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 3 Solving Continuous MDPs with Discretization -- CS287-FA19 Advanced Robotics at UC Berkeley",
        "description": "Instructor: Pieter Abbeel\nCourse Website: https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/mJlAfKc4990/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/mJlAfKc4990/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/mJlAfKc4990/hqdefault.jpg",
            "width": 480,
            "height": 360
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 31,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "mJlAfKc4990"
        },
        "videoOwnerChannelTitle": "Pieter Abbeel",
        "videoOwnerChannelId": "UC88M-XNc4BlzJVJvOyiHZDQ"
      },
      "contentDetails": {
        "videoId": "mJlAfKc4990",
        "videoPublishedAt": "2020-02-16T23:29:42Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "Excjvvw6H6YWGJOhK26_RT3Ic0g",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4zRDBDOEZDOUM0MDY5NEEz",
      "snippet": {
        "publishedAt": "2021-11-11T10:24:25Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 15 Partially Observable MDPs (POMDPs) -- CS287-FA19 Advanced Robotics at UC Berkeley",
        "description": "Instructor: Pieter Abbeel\nCourse Website: https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/2dNp7QyoF_k/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/2dNp7QyoF_k/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/2dNp7QyoF_k/hqdefault.jpg",
            "width": 480,
            "height": 360
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 32,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "2dNp7QyoF_k"
        },
        "videoOwnerChannelTitle": "Pieter Abbeel",
        "videoOwnerChannelId": "UC88M-XNc4BlzJVJvOyiHZDQ"
      },
      "contentDetails": {
        "videoId": "2dNp7QyoF_k",
        "videoPublishedAt": "2020-02-16T23:30:19Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "z2UPJUJnLMFvTfckmwTlakUv8nM",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5DQUNERDQ2NkIzRUQxNTY1",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Lecture 8: Markov Decision Processes - Reinforcement Learning | Stanford CS221: AI (Autumn 2019)",
        "description": "For more information about Stanford\u2019s Artificial Intelligence professional and graduate programs, visit: https://stanford.io/2Zv1JpK\n\nTopics: Reinforcement learning, Monte Carlo, SARSA, Q-learning, Exploration/exploitation, function approximation\nPercy Liang, Associate Professor & Dorsa Sadigh, Assistant Professor - Stanford University\nhttp://onlinehub.stanford.edu/\n\nAssociate Professor Percy Liang \nAssociate Professor of Computer Science and Statistics (courtesy)\nhttps://profiles.stanford.edu/percy-liang\n\nAssistant Professor Dorsa Sadigh\nAssistant Professor in the Computer Science Department & Electrical Engineering Department\nhttps://profiles.stanford.edu/dorsa-sadigh\n \nTo follow along with the course schedule and syllabus, visit: \nhttps://stanford-cs221.github.io/autumn2019/#schedule",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/HpaHTfY52RQ/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/HpaHTfY52RQ/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/HpaHTfY52RQ/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/HpaHTfY52RQ/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/HpaHTfY52RQ/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 33,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "HpaHTfY52RQ"
        },
        "videoOwnerChannelTitle": "stanfordonline",
        "videoOwnerChannelId": "UCBa5G_ESCn8Yd4vw5U-gIcg"
      },
      "contentDetails": {
        "videoId": "HpaHTfY52RQ",
        "videoPublishedAt": "2020-04-28T17:05:30Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "bCXzZ6HR8ZS5npIi3YTQ0GDhK-Y",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay41QUZGQTY5OTE4QTREQUU4",
      "snippet": {
        "publishedAt": "2021-11-11T10:24:07Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "L12 Representation Learning for Reinforcement Learning --- CS294-158 UC Berkeley Spring 2020",
        "description": "Course homepage:\nhttps://sites.google.com/view/berkeley-cs294-158-sp20/home\nLecture Instructors: Aravind Srinivas, Peter Chen\nCourse Instructors: Pieter Abbeel, Aravind Srinivas, Peter Chen, Jonathan Ho, Alex Li, Wilson Yan\nCS294-158-SP20: Deep Unsupervised Learning\nUC Berkeley, Spring 2020",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/YqvhDPd1UEw/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/YqvhDPd1UEw/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/YqvhDPd1UEw/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/YqvhDPd1UEw/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/YqvhDPd1UEw/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 34,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "YqvhDPd1UEw"
        },
        "videoOwnerChannelTitle": "Pieter Abbeel",
        "videoOwnerChannelId": "UC88M-XNc4BlzJVJvOyiHZDQ"
      },
      "contentDetails": {
        "videoId": "YqvhDPd1UEw",
        "videoPublishedAt": "2020-04-30T05:25:09Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "RR1FcnuawaN5yOaMj6mfAvjkUyE",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5EMEEwRUY5M0RDRTU3NDJC",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Alpha Zero and Monte Carlo Tree Search",
        "description": "Blog: http://joshvarty.github.io/AlphaZero/\nGitHub: https://github.com/JoshVarty/AlphaZeroSimple\nTwitch: http://twitch.tv/JoshVarty\n\nA discussion of Alpha Zero and Monte Carlo Tree Search",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/62nq4Zsn8vc/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/62nq4Zsn8vc/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/62nq4Zsn8vc/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/62nq4Zsn8vc/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/62nq4Zsn8vc/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 35,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "62nq4Zsn8vc"
        },
        "videoOwnerChannelTitle": "Josh Varty",
        "videoOwnerChannelId": "UC0HYDMj0RHzu7-i01n4FeUw"
      },
      "contentDetails": {
        "videoId": "62nq4Zsn8vc",
        "videoPublishedAt": "2020-05-24T20:50:05Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "wMl7v0sC3blE3qXczPe9C06hwFA",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay5GNDg1Njc1QzZERjlFRjE5",
      "snippet": {
        "publishedAt": "2021-11-17T14:11:12Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Deep Reinforcement Learning Tutorial for Python in 20 Minutes",
        "description": "Worked with supervised learning?\n\nMaybe you\u2019ve dabbled with unsupervised learning. \n\nBut what about reinforcement learning?\n\nIt can be a little tricky to get all setup with RL. You need to manage environments, build your DL models and work out how to save your models down so you can reuse them. But that shouldn\u2019t stop you! \n\nWhy?\n\nBecause they\u2019re powering the next generation of advancements in IOT environments and even gaming and the use cases for RL are growing by the minute. That being said, getting started doesn\u2019t need to be a pain, you can get up and running in just 20 minutes working with Keras-RL and OpenAI. \n\nIn this video you\u2019ll learn how to:\n1. Create OpenAI Gym environments like CartPole\n2. Build a Deep Learning model for Reinforcement Learning using Tensorflow and Keras\n3. Train a Reinforcement Learning model using Deep Q Policy based learning using Keras-RL\n\nGithub Repo for the Project: https://github.com/nicknochnack/TensorflowKeras-ReinforcementLearning\n\nWant to learn more about it all:\nOpen AI Gym: https://gym.openai.com/envs/\nKeras RL: https://keras-rl.readthedocs.io/\n\nOh, and don't forget to connect with me!\nLinkedIn: https://www.linkedin.com/in/nicholasrenotte\nFacebook: https://www.facebook.com/nickrenotte/\nGitHub: https://github.com/nicknochnack\n\nHappy coding!\nNick\n\nP.s. Let me know how you go and drop a comment if you need a hand!\n\nMusic by Lakey Inspired\nChill Day - https://www.youtube.com/watch?v=3HjG1Y4QpVA",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/cO5g5qLrLSo/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/cO5g5qLrLSo/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/cO5g5qLrLSo/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/cO5g5qLrLSo/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/cO5g5qLrLSo/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 36,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "cO5g5qLrLSo"
        },
        "videoOwnerChannelTitle": "Nicholas Renotte",
        "videoOwnerChannelId": "UCHXa4OpASJEwrHrLeIzw7Yg"
      },
      "contentDetails": {
        "videoId": "cO5g5qLrLSo",
        "videoPublishedAt": "2020-08-30T03:36:15Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "li-c6-Ui2nk1Wk-_XB3lYbUAS30",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay42MTI4Njc2QjM1RjU1MjlG",
      "snippet": {
        "publishedAt": "2021-11-11T10:25:28Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Q-Learning | Reinforcement Learning",
        "description": "Q-learning is a model-free reinforcement learning algorithm to learn a policy telling an agent what action to take under what circumstances. It does not require a model of the environment, and it can handle problems with stochastic transitions and rewards, without requiring adaptations. #QLearning #ReinforcementLearning #MachineLearning\n\n\ud83d\udc0d\ud835\udc77\ud835\udc9a\ud835\udc95\ud835\udc89\ud835\udc90\ud835\udc8f \ud835\udc7a\ud835\udc8c\ud835\udc8a\ud835\udc8d\ud835\udc8d \ud835\udc7a\ud835\udc86\ud835\udc93\ud835\udc8a\ud835\udc86\ud835\udc94 \ud83d\udc49 https://www.youtube.com/playlist?list=PLPN-43XehstMPOjguAFadcWvMnaefX4gf\n\n\ud83d\udc19\ud835\udc6b\ud835\udc86\ud835\udc86\ud835\udc91 \ud835\udc73\ud835\udc86\ud835\udc82\ud835\udc93\ud835\udc8f\ud835\udc8a\ud835\udc8f\ud835\udc88 \ud83d\udc49 https://www.youtube.com/playlist?list=PLPN-43XehstM4-SWLIUS5eFxPmFJ3iHan\n\n\ud83e\uddbe\ud835\udc74\ud835\udc82\ud835\udc84\ud835\udc89\ud835\udc8a\ud835\udc8f\ud835\udc86 \ud835\udc73\ud835\udc86\ud835\udc82\ud835\udc93\ud835\udc8f\ud835\udc8a\ud835\udc8f\ud835\udc88 \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstOjGY6vM6nBpSggHoAv9hkR\n\n\ud83e\udd16\ud835\udc68\ud835\udc93\ud835\udc95\ud835\udc8a\ud835\udc87\ud835\udc8a\ud835\udc84\ud835\udc8a\ud835\udc82\ud835\udc8d \ud835\udc70\ud835\udc8f\ud835\udc95\ud835\udc86\ud835\udc8d\ud835\udc8d\ud835\udc8a\ud835\udc88\ud835\udc86\ud835\udc8f\ud835\udc84\ud835\udc86 \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstNQttedytmmLPwzMCXahBRg\n\n\u2601\ufe0f\ud835\udc6a\ud835\udc8d\ud835\udc90\ud835\udc96\ud835\udc85 \ud835\udc6a\ud835\udc90\ud835\udc8e\ud835\udc91\ud835\udc96\ud835\udc95\ud835\udc8a\ud835\udc8f\ud835\udc88 \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstNd5WsXQ9y3GFXyagkX1PC3\n\n\ud83d\udcf6\ud835\udc7e\ud835\udc8a\ud835\udc93\ud835\udc86\ud835\udc8d\ud835\udc86\ud835\udc94\ud835\udc94 \ud835\udc7b\ud835\udc86\ud835\udc84\ud835\udc89\ud835\udc8f\ud835\udc90\ud835\udc8d\ud835\udc90\ud835\udc88\ud835\udc9a \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstMhFEXiOgJwv2Ec3vOTWpSH\n\n\ud83d\udee0\ufe0f\ud835\udc6b\ud835\udc82\ud835\udc95\ud835\udc82 \ud835\udc74\ud835\udc8a\ud835\udc8f\ud835\udc8a\ud835\udc8f\ud835\udc88 \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstOe0CxcXaYeLTFpgD2IiluP\n\n\u2699\ufe0f\ud835\udc7a\ud835\udc8a\ud835\udc8e\ud835\udc96\ud835\udc8d\ud835\udc82\ud835\udc95\ud835\udc8a\ud835\udc90\ud835\udc8f \ud835\udc74\ud835\udc90\ud835\udc85\ud835\udc86\ud835\udc8d\ud835\udc8a\ud835\udc8f\ud835\udc88 \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstPwUMDCs9zYQS-e5-0zjifX\n\n\ud83d\udc18\ud835\udc69\ud835\udc8a\ud835\udc88 \ud835\udc6b\ud835\udc82\ud835\udc95\ud835\udc82 \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstPr1D-t9X2klE--Uj4YSNwn\n\n\u26d3\ufe0f\ud835\udc69\ud835\udc8d\ud835\udc90\ud835\udc84\ud835\udc8c\ud835\udc84\ud835\udc89\ud835\udc82\ud835\udc8a\ud835\udc8f \ud835\udc7b\ud835\udc86\ud835\udc84\ud835\udc89\ud835\udc8f\ud835\udc90\ud835\udc8d\ud835\udc90\ud835\udc88\ud835\udc9a \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstNgC2t_EScmj1GWv24ncugJ\n\n\ud83d\udca1\ud835\udc70\ud835\udc76\ud835\udc7b \ud83d\udc49https://www.youtube.com/playlist?list=PLPN-43XehstOS_3mv9LgFWnVXQE-7PKbF\n\n\n\ud835\udcd5\ud835\udcf8\ud835\udcf5\ud835\udcf5\ud835\udcf8\ud835\udd00 \ud835\udcf6\ud835\udcee \ud835\udcf8\ud835\udcf7 \ud835\udcd8\ud835\udcf7\ud835\udcfc\ud835\udcfd\ud835\udcea\ud835\udcf0\ud835\udcfb\ud835\udcea\ud835\udcf6 \ud83d\udc49 https://www.instagram.com/adhyapakh/\n\ud835\udce5\ud835\udcf2\ud835\udcfc\ud835\udcf2\ud835\udcfd \ud835\udcf6\ud835\udd02 \ud835\udcdf\ud835\udcfb\ud835\udcf8\ud835\udcef\ud835\udcf2\ud835\udcf5\ud835\udcee \ud83d\udc49 https://www.linkedin.com/in/reng99/\n(Feel free to give or ask for any recommendation)\n\ud835\udce2\ud835\udcfe\ud835\udcf9\ud835\udcf9\ud835\udcf8\ud835\udcfb\ud835\udcfd \ud835\udcf6\ud835\udd02 \ud835\udd00\ud835\udcf8\ud835\udcfb\ud835\udcf4 \ud835\udcf8\ud835\udcf7 \ud835\udcdf\ud835\udcea\ud835\udcfd\ud835\udcfb\ud835\udcee\ud835\udcf8\ud835\udcf7 \ud83d\udc49 https://www.patreon.com/ranjiraj\n\ud835\udcd6\ud835\udcf2\ud835\udcfd\ud835\udcd7\ud835\udcfe\ud835\udceb\ud83d\udc49 https://github.com/ranjiGT",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/4dcgjcuR-1o/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/4dcgjcuR-1o/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/4dcgjcuR-1o/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/4dcgjcuR-1o/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/4dcgjcuR-1o/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 37,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "4dcgjcuR-1o"
        },
        "videoOwnerChannelTitle": "RANJI RAJ",
        "videoOwnerChannelId": "UCl1Tqc3U-TAOjuh4izHLsUw"
      },
      "contentDetails": {
        "videoId": "4dcgjcuR-1o",
        "videoPublishedAt": "2020-10-01T16:53:12Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "pB99furMpDv4nCOXd3TqN2k5OY8",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay45NDk1REZENzhEMzU5MDQz",
      "snippet": {
        "publishedAt": "2021-11-08T14:32:09Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Policy and Value Iteration",
        "description": "",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/l87rgLg90HI/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/l87rgLg90HI/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/l87rgLg90HI/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/l87rgLg90HI/sddefault.jpg",
            "width": 640,
            "height": 480
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 38,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "l87rgLg90HI"
        },
        "videoOwnerChannelTitle": "CIS 522 - Deep Learning",
        "videoOwnerChannelId": "UCT1ejuxsdomILyc5I2EdzYg"
      },
      "contentDetails": {
        "videoId": "l87rgLg90HI",
        "videoPublishedAt": "2021-03-28T21:48:58Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "HMBMnkP5gDTDSiMnlH9yHEjNWwc",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay41QTY1Q0UxMTVCODczNThE",
      "snippet": {
        "publishedAt": "2021-11-09T09:06:43Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "EfficientZero: Mastering Atari Games with Limited Data (Machine Learning Research Paper Explained)",
        "description": "#efficientzero #muzero #atari\n\nReinforcement Learning methods are notoriously data-hungry. Notably, MuZero learns a latent world model just from scalar feedback of reward- and policy-predictions, and therefore relies on scale to perform well. However, most RL algorithms fail when presented with very little data. EfficientZero makes several improvements over MuZero that allows it to learn from astonishingly small amounts of data and outperform other methods by a large margin in the low-sample setting. This could be a staple algorithm for future RL research.\n\nOUTLINE:\n0:00 - Intro & Outline\n2:30 - MuZero Recap\n10:50 - EfficientZero improvements\n14:15 - Self-Supervised consistency loss\n17:50 - End-to-end prediction of the value prefix\n20:40 - Model-based off-policy correction\n25:45 - Experimental Results & Conclusion\n\nPaper: https://arxiv.org/abs/2111.00210\nCode: https://github.com/YeWR/EfficientZero\nNote: code not there yet as of release of this video\n\nAbstract:\nReinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 190.4% mean human performance and 116.0% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at this https URL. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.\n\nAuthors: Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, Yang Gao\n\nLinks:\nTabNine Code Completion (Referral): http://bit.ly/tabnine-yannick\nYouTube: https://www.youtube.com/c/yannickilcher\nTwitter: https://twitter.com/ykilcher\nDiscord: https://discord.gg/4H8xxDF\nBitChute: https://www.bitchute.com/channel/yannic-kilcher\nMinds: https://www.minds.com/ykilcher\nParler: https://parler.com/profile/YannicKilcher\nLinkedIn: https://www.linkedin.com/in/ykilcher\nBiliBili: https://space.bilibili.com/1824646584\n\nIf you want to support me, the best thing to do is to share out the content :)\n\nIf you want to support me financially (completely optional and voluntary, but a lot of people have asked for this):\nSubscribeStar: https://www.subscribestar.com/yannickilcher\nPatreon: https://www.patreon.com/yannickilcher\nBitcoin (BTC): bc1q49lsw3q325tr58ygf8sudx2dqfguclvngvy2cq\nEthereum (ETH): 0x7ad3513E3B8f66799f507Aa7874b1B0eBC7F85e2\nLitecoin (LTC): LQW2TRyKYetVC8WjFkhpPhtpbDM4Vw7r9m\nMonero (XMR): 4ACL8AGrEo5hAir8A9CeVrW8pEauWvnp1WnSDZxW7tziCDLhZAGsgzhRQABDnFy8yuM9fWJDviJPHKRjV4FWt19CJZN9D4n",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/NJCLUzkn-sA/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/NJCLUzkn-sA/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/NJCLUzkn-sA/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/NJCLUzkn-sA/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/NJCLUzkn-sA/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 39,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "NJCLUzkn-sA"
        },
        "videoOwnerChannelTitle": "Yannic Kilcher",
        "videoOwnerChannelId": "UCZHmQk67mSJgfCCTn7xBfew"
      },
      "contentDetails": {
        "videoId": "NJCLUzkn-sA",
        "videoPublishedAt": "2021-11-03T15:54:39Z"
      }
    },
    {
      "kind": "youtube#playlistItem",
      "etag": "DfYywp0Arq9hmYpQddtWrVfH19w",
      "id": "UExJamhmbHVoTmQ5X0ZreEQzakxmb053ckxfbzJKcmJyay4zQzFBN0RGNzNFREFCMjBE",
      "snippet": {
        "publishedAt": "2021-11-18T04:53:48Z",
        "channelId": "UCqsUJL5xIWuidR7sIrPLhAw",
        "title": "Human-in-the-Loop Reinforcement Learning",
        "description": "(Pieter Abbeel, UC Berkeley |  Covariant)\n\nPieter Abbeel is Professor at UC Berkeley, where he is Director of the Berkeley Robot Learning Lab and Co-Director of the Berkeley Artificial Intelligence (BAIR) Lab. Abbeel\u2019s research strives to build ever more intelligent systems, with main emphasis on deep reinforcement learning, meta-learning. His lab also investigates how AI could advance other science and engineering disciplines. Abbeel has founded several companies, including Gradescope (AI to help instructors with grading homework and exams), Covariant (AI for robotic automation of warehouses and factories). Abbeel is also the host of The Robot Brains Podcast. Abbeel has received many awards and honors, including the PECASE, NSF-CAREER, ONR-YIP, Darpa-YFA, TR35. His work is frequently featured in the press, including the New York Times, Wall Street Journal, BBC, Rolling Stone, Wired, and Tech Review.",
        "thumbnails": {
          "default": {
            "url": "https://i.ytimg.com/vi/LEzdi-eJR8k/default.jpg",
            "width": 120,
            "height": 90
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/LEzdi-eJR8k/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "high": {
            "url": "https://i.ytimg.com/vi/LEzdi-eJR8k/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/LEzdi-eJR8k/sddefault.jpg",
            "width": 640,
            "height": 480
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/LEzdi-eJR8k/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          }
        },
        "channelTitle": "Donald Thompson",
        "playlistId": "PLIjhfluhNd9_FkxD3jLfoNwrL_o2Jrbrk",
        "position": 40,
        "resourceId": {
          "kind": "youtube#video",
          "videoId": "LEzdi-eJR8k"
        },
        "videoOwnerChannelTitle": "Anyscale",
        "videoOwnerChannelId": "UC7L1tZw52rtgmIB4fr_f40w"
      },
      "contentDetails": {
        "videoId": "LEzdi-eJR8k",
        "videoPublishedAt": "2021-11-17T21:42:08Z"
      }
    }
  ]
}